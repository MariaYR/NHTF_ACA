library (Hmisc)
?Hmisc
??Hmis
??Hmisc
install.packages("Hmisc")
library (Hmisc)
library (Hmisc)
Rd1<- read.csv("/Users/mboogie/Dropbox/El Centro/ECDLR Prelim Analysis/rd1.csv",header = (TRUE))
Rd2<- read.csv("/Users/mboogie/Dropbox/El Centro/ECDLR Prelim Analysis/rd1.csv",header = (TRUE))
RD1 <- na.omit(Rd1)
RD2 <- na.omit(Rd2)
describe(mydata)
describe(RD1)
summary (RD1)
mytable <- table(RD1$Age, RD1$Income, RD1$PITI)
ftable(mytable)
ftable(mytable)
summary (RD1)
mytable <- table(RD1$Race, RD1$Ethnicity, RD1$Gender)
ftable(mytable)
mytable <- xtabs(~Race+Ethnicity+Gender, data=RD1)
ftable(mytable)
summary(mytable)
summary (RD2)
prop.table(mytable)
attach (RD1)
mytable <- table(Race,Ethnicity) # A will be rows, B will be columns
mytable
prop.table(mytable)
summary(mytable)
summary (RD1)
detach (RD1)
attach (RD1)
mytable <- table(Race,Ethnicity) # A will be rows, B will be columns
mytable # print table
prop.table(mytable)
summary(mytable) # chi-square test of indepedence
mytable1 <- table(DefaultReasonCode,LoanStatusAtContact) # A will be rows, B will be columns
mytable1 # print table
prop.table(mytable1)
summary(mytable1) # chi-square test of indepedence
mytable2 <- table (LoanProductType, CounselingOutcomeCode)# A will be rows, B will be columns
mytable2
prop.table(mytable2)
mytable3 <- table(DefaultReasonCode,Gender) # A will be rows, B will be columns
mytable3 # print table
prop.table(mytable3)
mytable3 <- table(DefaultReasonCode,HouseholdType) # A will be rows, B will be columns
mytable3 # print table
prop.table(mytable3)
detach (RD1)
attach (RD2)
mytable <- table(Race,Ethnicity) # A will be rows, B will be columns
mytable
prop.table(mytable)
mytable1 <- table(DefaultReasonCode,LoanStatusAtContact) # A will be rows, B will be columns
mytable1 # print table
prop.table(mytable1)
Rd2<- read.csv("/Users/mboogie/Dropbox/El Centro/ECDLR Prelim Analysis/rd7.csv",header = (TRUE))
RD2 <- na.omit(Rd2)
describe(RD1)
summary (RD2)
attach (RD2)
mytable <- table(Race,Ethnicity) # A will be rows, B will be columns
mytable # print table
prop.table(mytable)
mytable1 <- table(DefaultReasonCode,LoanStatusAtContact) # A will be rows, B will be columns
mytable1 # print table
prop.table(mytable1)
mytable2 <- table (LoanProductType, CounselingOutcomeCode)# A will be rows, B will be columns
mytable2
prop.table(mytable2)
mytable2 # print table
prop.table(mytable2)
mytable3 <- table(DefaultReasonCode,HouseholdType) # A will be rows, B will be columns
mytable3 # print table
prop.table(mytable3)
detach (RD2)
save.image("~/Dropbox/El Centro/ECDLR Prelim Analysis/Prelim_Analysis.RData")
summary (RD2)
install.packages ("rMarkdown")
install.packages ("rmarkdown")
install.packages ("tex")
install.packages ("TeX")
load("~/Dropbox/#WhyIStayed/#WhyIStayed.RData")
library(RTextTools)
excerpts<- read.csv("~/Dropbox/#WhyIStayed/BEV_Final.csv",header = (TRUE))
matrix <- create_matrix(cbind(excerpts["text"]), language="english",
removeNumbers=TRUE, stemWords=FALSE)
container <- create_container(matrix,excerpts$text,trainSize=1:71, testSize=72:111,virgin=TRUE)
container
example_mat <- container@training_matrix
example_names <- container@column_names
example_mat2 <- as.matrix(example_mat)
colnames(example_mat2) <- example_names
example_mat2[1:10,1:10]
save.image("~/Dropbox/#WhyIStayed/#WhyIStayed.RData")
SLDA <- train_model(container,"SLDA")
BOOSTING <- train_model(container,"BOOSTING")
BAGGING <- train_model(container,"BAGGING")
RF <- train_model(container,"RF")
NNET <- train_model(container,"NNET")
TREE <- train_model(container,"TREE")
save.image("~/Dropbox/#WhyIStayed/#WhyIStayed.RData")
SVM_CLASSIFY <- classify_model(container, SVM)
SVM_CLASSIFY <- classify_model(container, "SVM")
SVM_CLASSIFY <- classify_model(container, SVM)
SVM_CLASSIFY <- classify_model(container, SVM)
SVM <- train_model(container,"SVM") #runs fine
SVM_CLASSIFY <- classify_model(container, SVM)
BOOSTING_CLASSIFY <- classify_model(container, BOOSTING)
BAGGING_CLASSIFY <- classify_model(container, BAGGING)
RF_CLASSIFY <- classify_model(container, RF)
NNET_CLASSIFY <- classify_model(container, NNET)
analytics <- create_analytics(container,cbind(SVM_CLASSIFY,
BOOSTING_CLASSIFY, BAGGING_CLASSIFY, NNET_CLASSIFY))
analyticsSVM <- create_analytics(container,SVM_CLASSIFY)
SVM_CLASSIFY
names(SVM_CLASSIFY)
citation()
install.packages("citation")
citation (package="twitteR")
help(citation)
citation(package="streamR")
analyticsSVM <- create_analytics(container,SVM_CLASSIFY)
library(twitteR)
library(streamR)
library(plyr)
library(stringr)
library(RTextTools)
analyticsSVM <- create_analytics(container,SVM_CLASSIFY)
table (SVM_CLASSIFY)
analyticsSVM <- create_analytics(container,SVM_CLASSIFY)
analyticsSVM <- create_analytics(container, cbind(SVM_CLASSIFY))
View(BEV_Final)
range (BEV_Final$created_at)
analyticsBOOSTING <- create_analytics(container,BOOSTING_CLASSIFY)
analyticsBAGGING <- create_analytics(container,BAGGING_CLASSIFY)
analyticsNNET <- create_analytics(container,NNET_CLASSIFY)
names(SVM_CLASSIFY)
table(SVM_CLASSIFY)
plot(d, main="Distribution of Sentiment Scores (N= 111)",
xlab="Score", ylab="Density",
abline(v=mean(BEV_Scores), col="red")) # plots the results
plot(d, main="Distribution of @BevTGooden Tweets' Sentiment Scores (N= 111)",
xlab="Score", ylab="Density",
abline(v=mean(BEV_Scores), col="red"))
container
matrix
install.packages ("topicmodels")
library ("topicmodels")
k <- length(excerpts)
lda <- LDA(matrix, k)
terms(lda)
topics(lda)
matrix <- create_matrix(cbind(excerpts["text"]), language="english",
removeNumbers=TRUE, stemWords=TRUE, removePunctuation =TRUE,
removeStopwords=TRUE, stripWhitespace=TRUE)
library(RTextTools)
matrix <- create_matrix(cbind(excerpts["text"]), language="english",
removeNumbers=TRUE, stemWords=TRUE, removePunctuation =TRUE,
removeStopwords=TRUE, stripWhitespace=TRUE)
matrix
k <- length(excerpts)
lda <- LDA(matrix, k)
terms(lda)
topics(lda)
install.packages ("libcurl")
install.packages("libcurl")
terms(lda)
topics(lda)
install.packages("lsa")
install.packages("SnowballC")
install.packages("ggplot2")
install.packages("tm")
install.packages("tm")
install.packages("tm")
library("tm", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
detach("package:tm", unload=TRUE)
library("tm", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library(twitteR)
library(streamR)
source('functions_by_pablobarbera.R')
if(nchar(system.file(package="foreach"))) citation("foreach")
load("~/Desktop/NHTF_ACA/R/PSJ_6.29.15.RData")
library(RTextTools)
analytics <- create_analytics(DCcontainer,cbind(SVM_CLASSIFY, GLMNET_CLASSIFY, SLDA_CLASSIFY,  BOOSTING_CLASSIFY, BAGGING_CLASSIFY, RF_CLASSIFY, TREE_CLASSIFY))
head(analytics@algorithm_summary)
head(analytics@label_summary)
save.image("~/Desktop/NHTF_ACA/R/PSJ_6.29.15.RData")
head(analytics@document_summary)
analytics@ensemble_summary
summary(analytics)
setwd("~/Desktop/NHTF_ACA/results")
write.csv(analytics@algorithm_summary,"DeepCore_AlgorithmSummary.csv")
write.csv(analytics@label_summary,"DeepCore_LabelSummary.csv")
write.csv(analytics@document_summary,"DeepCore_DocumentSummary.csv")
write.csv(analytics@ensemble_summary,"DeepCore_EnsembleSummary.csv")
write.csv(summary(analytics),"DeepCore_Summary.csv")
x <- as.numeric(rownames(analytics@algorithm_summary))[-20]
y <- analytics@algorithm_summary$SVM_RECALL[-20]
plot(x, y, type="l", lwd=3, main="Support Vector Machine Deep Core Beliefs Code Accuracy", ylab="Recall Accuracy", xlab="Code")
abline(h=.75, lwd=2, col="maroon")
text(x, y, adj=1.2)
head(analytics@algorithm_summary)
x <- as.numeric(rownames(analytics@algorithm_summary))[-20]
y <- analytics@algorithm_summary$SLDA_RECALL[-20]
plot(x, y, type="l", lwd=3, main="SLDA Deep Core Beliefs Code Accuracy", ylab="Recall Accuracy", xlab="Code")
abline(h=.75, lwd=2, col="maroon")
text(x, y, adj=1.2)
x <- as.numeric(rownames(analytics@algorithm_summary))[-20]
y <- analytics@algorithm_summary$SVM_RECALL[-20]
plot(x, y, type="l", lwd=3, main="Boosting Deep Core Beliefs Code Accuracy", ylab="Recall Accuracy", xlab="Code")
abline(h=.75, lwd=2, col="maroon")
text(x, y, adj=1.2)
x <- as.numeric(rownames(analytics@algorithm_summary))[-20]
y <- analytics@algorithm_summary$SVM_RECALL[-20]
plot(x, y, type="l", lwd=3, main="Bagging Deep Core Beliefs Code Accuracy", ylab="Recall Accuracy", xlab="Code")
abline(h=.75, lwd=2, col="maroon")
text(x, y, adj=1.2)
x <- as.numeric(rownames(analytics@algorithm_summary))[-20]
y <- analytics@algorithm_summary$SVM_RECALL[-20]
plot(x, y, type="l", lwd=3, main="Random Forest Deep Core Beliefs Code Accuracy", ylab="Recall Accuracy", xlab="Code")
abline(h=.75, lwd=2, col="maroon")
text(x, y, adj=1.2)
x <- as.numeric(rownames(analytics@algorithm_summary))[-20]
y <- analytics@algorithm_summary$SVM_RECALL[-20]
plot(x, y, type="l", lwd=3, main="Support Vector Machine Deep Core Beliefs Code Accuracy", ylab="Recall Accuracy", xlab="Code")
abline(h=.75, lwd=2, col="maroon")
text(x, y, adj=1.2)
x <- as.numeric(rownames(analytics@algorithm_summary))[-20]
y <- analytics@algorithm_summary$SLDA_RECALL[-20]
plot(x, y, type="l", lwd=3, main="SLDA Deep Core Beliefs Code Accuracy", ylab="Recall Accuracy", xlab="Code")
abline(h=.75, lwd=2, col="maroon")
text(x, y, adj=1.2)
x <- as.numeric(rownames(analytics@algorithm_summary))[-20]
y <- analytics@algorithm_summary$LOGITBOOST_RECALL[-20]
plot(x, y, type="l", lwd=3, main="Boosting Deep Core Beliefs Code Accuracy", ylab="Recall Accuracy", xlab="Code")
abline(h=.75, lwd=2, col="maroon")
text(x, y, adj=1.2)
x <- as.numeric(rownames(analytics@algorithm_summary))[-20]
y <- analytics@algorithm_summary$BAGGING_RECALL[-20]
plot(x, y, type="l", lwd=3, main="Bagging Deep Core Beliefs Code Accuracy", ylab="Recall Accuracy", xlab="Code")
abline(h=.75, lwd=2, col="maroon")
text(x, y, adj=1.2)
x <- as.numeric(rownames(analytics@algorithm_summary))[-20]
y <- analytics@algorithm_summary$BAGGING_RECALL[-20]
plot(x, y, type="l", lwd=3, main="Bagging Deep Core Beliefs Code Accuracy", ylab="Recall Accuracy", xlab="Code")
abline(h=.75, lwd=2, col="maroon")
text(x, y, adj=1.2)
x <- as.numeric(rownames(analytics@algorithm_summary))[-20]
y <- analytics@algorithm_summary$FORESTS_RECALL[-20]
plot(x, y, type="l", lwd=3, main="Random Forest Deep Core Beliefs Code Accuracy", ylab="Recall Accuracy", xlab="Code")
abline(h=.75, lwd=2, col="maroon")
text(x, y, adj=1.2)
x <- as.numeric(rownames(analytics@algorithm_summary))[-20]
y <- analytics@algorithm_summary$GLMNET_RECALL[-20]
plot(x, y, type="l", lwd=3, main="GLM_NET Machine Deep Core Beliefs Code Accuracy", ylab="Recall Accuracy", xlab="Code")
abline(h=.75, lwd=2, col="maroon")
text(x, y, adj=1.2)
x <- as.numeric(rownames(analytics@algorithm_summary))[-20]
y <- analytics@algorithm_summary$TREE_RECALL[-20]
plot(x, y, type="l", lwd=3, main="Support Vector Machine Deep Core Beliefs Code Accuracy", ylab="Recall Accuracy", xlab="Code")
abline(h=.75, lwd=2, col="maroon")
text(x, y, adj=1.2)
x <- as.numeric(rownames(analytics@algorithm_summary))[-20]
y <- analytics@algorithm_summary$TREE_RECALL[-20]
plot(x, y, type="l", lwd=3, main="TREE Deep Core Beliefs Code Accuracy", ylab="Recall Accuracy", xlab="Code")
abline(h=.75, lwd=2, col="maroon")
text(x, y, adj=1.2)
table(true = analytics@document_summary$MANUAL_CODE, predict = analytics@document_summary$CONSENSUS_CODE)
table(true = analytics@document_summary$MANUAL_CODE, predict = analytics@document_summary$PROBABILITY_CODE)
table(true = analytics@document_summary$MANUAL_CODE, predict = analytics@document_summary$SVM_LABEL)
table(true = analytics@document_summary$MANUAL_CODE, predict = analytics@document_summary$BOOSTING_LABEL)
table(true = analytics@document_summary$MANUAL_CODE, predict = analytics@document_summary$RF_LABEL)
table(true = analytics@document_summary$MANUAL_CODE, predict = analytics@document_summary$TREE_LABEL)
table(true = analytics@document_summary$MANUAL_CODE, predict = analytics@document_summary$SLDA_LABEL)
table(true = analytics@document_summary$MANUAL_CODE, predict = analytics@document_summary$BAGGING_LABEL)
recall_accuracy (analytics@document_summary$MANUAL_CODE, analytics@document_summary$CONSENSUS_CODE)
recall_accuracy (analytics@document_summary$MANUAL_CODE, analytics@document_summary$PROBABILITY_CODE)
recall_accuracy (analytics@document_summary$MANUAL_CODE, analytics@document_summary$SVM_LABEL)
recall_accuracy (analytics@document_summary$MANUAL_CODE, analytics@document_summary$BOOSTING_LABEL)
recall_accuracy (analytics@document_summary$MANUAL_CODE, analytics@document_summary$RF_LABEL)
recall_accuracy (analytics@document_summary$MANUAL_CODE, analytics@document_summary$TREE_LABEL)
recall_accuracy (analytics@document_summary$MANUAL_CODE, analytics@document_summary$SLDA_LABEL)
recall_accuracy (analytics@document_summary$MANUAL_CODE, analytics@document_summary$BAGGING_LABEL)
analytics@ensemble_summary
DeepCore_Final <- analytics@document_summary
DeepCore_Final$recall_ensemble[DeepCore_Final$CONSENSUS_AGREE == 2] <- "88% recall"
DeepCore_Final$recall_ensemble[DeepCore_Final$CONSENSUS_AGREE == 1] <- "72% recall"
head(DeepCore_Final)
getwd()
write.csv(DeepCore_Final, "test_deepcore_beliefs_coded.csv", row.names=FALSE)
save.image("~/Desktop/NHTF_ACA/R/PSJ_6.29.15.RData")
save.image("~/Desktop/NHTF_ACA/R/PSJ_6.30.15.RData")
